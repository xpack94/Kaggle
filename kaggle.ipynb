{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from skimage.restoration import *\n",
    "from skimage import data, img_as_float\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 100, 100) (2000, 100, 100) (2000, 31)\n"
     ]
    }
   ],
   "source": [
    "train = np.load(\"./train_images.npy\", encoding = 'bytes')\n",
    "test = np.load(\"./test_images.npy\", encoding = 'bytes')\n",
    "train_labels = pd.read_csv(\"./train_labels.csv\")\n",
    "\n",
    "x_train = train[:,1]\n",
    "x_test = test[:,1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "train_labs = pd.factorize(train_labels['Category'])\n",
    "train_lab = train_labs[0]\n",
    "\n",
    "x_train = np.array([np.array(x) for x in x_train])\n",
    "x_test = np.array([np.array(x) for x in x_test])\n",
    "\n",
    "x_train = x_train.reshape((10000,100,100))\n",
    "x_test = x_test.reshape((10000,100,100))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_lab)\n",
    "x_train,y_train = shuffle(x_train,y_train, random_state = 0)\n",
    "\n",
    "train_X = x_train[:8000]\n",
    "train_y = y_train[:8000]\n",
    "test_X = x_train[8000:]\n",
    "test_y = y_train[8000:]\n",
    "IMAGE_SIZE = 100\n",
    "print(train_X.shape,test_X.shape,test_y.shape)\n",
    "\n",
    "z = train_labels.drop_duplicates('Category')\n",
    "z= z.reset_index()\n",
    "z = z['Category']\n",
    "label_dict = z.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fadee585710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAChCAYAAABaigMvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadee8d46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_X[0], (100,100))\n",
    "curr_lbl = np.argmax(y_train[0])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "# plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test_X[0], (100,100))\n",
    "curr_lbl = np.argmax(y_train[0])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "# plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def denoise(noisy,s1,s2,s3,s4):\n",
    "    se1 = cv2.getStructuringElement(cv2.MORPH_RECT, (s1,s1))\n",
    "    se2 = cv2.getStructuringElement(cv2.MORPH_RECT, (s2,s2))\n",
    "    se3 = cv2.getStructuringElement(cv2.MORPH_RECT, (s3,s3))\n",
    "    se4 = cv2.getStructuringElement(cv2.MORPH_RECT, (s4,s4))\n",
    "    mask = cv2.morphologyEx(noisy, cv2.MORPH_CLOSE, se1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se3)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se4)\n",
    "\n",
    "    out = (noisy * mask)/255\n",
    "    return out\n",
    "\n",
    "\n",
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = (-25,25)\n",
    "    return sk.transform.rotate(image_array, random_degree, preserve_range=True).astype(np.uint8)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    # add random noise to the image\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "curr_img = np.reshape(test_X[0], (100,100))\n",
    "curr_lbl = np.argmax(y_train[0])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.imshow(denoise(test_X[1],8,4,4,1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr1_X = train_X.copy()\n",
    "te1_X = test_X.copy()\n",
    "tr2_X = train_X.copy()\n",
    "te2_X = test_X.copy()\n",
    "for i in tqdm(range(len(train_X)),desc='denoising train'):\n",
    "    tr1_X[i] = denoise(tr1_X[i],7,5,5,1)\n",
    "for i in tqdm(range(len(test_X)),desc='denoising test'):\n",
    "    te1_X[i] = denoise(te1_X[i],7,5,5,1)\n",
    "\n",
    "for i in tqdm(range(len(train_X)),desc='denoising train'):\n",
    "    tr2_X[i] = denoise(tr2_X[i],5,5,5,1)\n",
    "for i in tqdm(range(len(test_X)),desc='denoising test'):\n",
    "    te2_X[i] = denoise(te2_X[i],5,5,5,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tr_randrot = random_rotation(train_X)\n",
    "tr_hor_flip = horizontal_flip(train_X)\n",
    "# te_randrot = random_rotation(train_X)\n",
    "# te_hor_flip = horizontal_flip(test_X)\n",
    "\n",
    "train_X = np.row_stack((train_X,tr_hor_flip))\n",
    "# test_X = np.row_stack((test_X,te_X,te_randrot,te_hor_flip))\n",
    "train_y = np.row_stack((train_y,train_y))\n",
    "# test_y = np.row_stack((test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(tr_randrot[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, train_y = shuffle(train_X,train_y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def central_scale_images(X_imgs, scales):\n",
    "    # Various settings needed for Tensorflow operation\n",
    "    boxes = np.zeros((len(scales), 4), dtype = np.float32)\n",
    "    for index, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - 0.5 * scale # To scale centrally\n",
    "        x2 = y2 = 0.5 + 0.5 * scale\n",
    "        boxes[index] = np.array([y1, x1, y2, x2], dtype = np.float32)\n",
    "    box_ind = np.zeros((len(scales)), dtype = np.int32)\n",
    "    crop_size = np.array([IMAGE_SIZE, IMAGE_SIZE], dtype = np.int32)\n",
    "    \n",
    "    X_scale_data = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (?, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    # Define Tensorflow operation for all scales but only one base image at a time\n",
    "    tf_img = tf.image.crop_and_resize(X, boxes, box_ind, crop_size)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for img_data in X_imgs:\n",
    "            batch_img = np.expand_dims(img_data, axis = 0)\n",
    "            scaled_imgs = sess.run(tf_img, feed_dict = {X: batch_img})\n",
    "            X_scale_data.extend(scaled_imgs)\n",
    "    \n",
    "    X_scale_data = np.array(X_scale_data, dtype = np.float32)\n",
    "    return X_scale_data\n",
    "\t\n",
    "# Produce each image at scaling of 90%, 75% and 60% of original image.\n",
    "scaled_imgs = central_scale_images(train_X, [0.90, 0.75, 0.60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_img = np.reshape(train_X[0], (100,100))\n",
    "plt.imshow(curr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 100, 100, 1) (2000, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape training and testing image\n",
    "train_X = train_X.reshape(-1, 100, 100, 1)\n",
    "test_X = test_X.reshape(-1,100,100,1)\n",
    "print(train_X.shape,test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def images_preprocessing(images):\n",
    "    list_hog_fd = []\n",
    "    for feature in tqdm(images):\n",
    "            fd = hog(feature, orientations=196, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "            list_hog_fd.append(fd)\n",
    "    return np.array(list_hog_fd, 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_iters = 200 \n",
    "learning_rate = 0.01 \n",
    "batch_size = 128\n",
    "\n",
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 100\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#both placeholders are of type float\n",
    "x = tf.placeholder(\"float\", [None, 100,100,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,16), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,16,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "#     'wc4': tf.get_variable('W3', shape=(3,3,128,256), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wd1': tf.get_variable('W4', shape=(13*13*64,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W6', shape=(64,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(16), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "#     'bc4': tf.get_variable('B3', shape=(256), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B4', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B5', shape=(n_classes), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    print(conv1)\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(conv1)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    print(conv2)\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(conv2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    print(conv3)\n",
    "\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    print(conv3)\n",
    "    \n",
    "#     conv4 = conv2d(conv3, weights['wc4'], biases['bc4'])\n",
    "#     print(conv4)\n",
    "\n",
    "#     # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "#     conv4 = maxpool2d(conv4, k=2)\n",
    "#     print(conv4)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print(fc1)\n",
    "\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    print(out)\n",
    "    drop = tf.layers.dropout(inputs=out, rate=0.4)\n",
    "    print(drop)\n",
    "\n",
    "    return drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 100, 100, 16), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 50, 50, 16), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 50, 50, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 25, 25, 32), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 25, 25, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 13, 13, 64), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 10816), dtype=float32)\n",
      "Tensor(\"Add_1:0\", shape=(?, 31), dtype=float32)\n",
      "Tensor(\"dropout/Identity:0\", shape=(?, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [03:15<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 3.358326, Training Accuracy= 0.06250\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.06000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:52<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1, Loss= 3.357289, Training Accuracy= 0.06250\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.06000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:51<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2, Loss= 3.356713, Training Accuracy= 0.06250\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.06000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [03:58<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3, Loss= 3.356353, Training Accuracy= 0.06250\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.06000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [04:49<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4, Loss= 3.356038, Training Accuracy= 0.06250\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "#         train_X, train_y = shuffle(train_X,train_y, random_state = 0)\n",
    "        for batch in tqdm(range(len(train_X)//batch_size)):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]   \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def autoencoder(inputs):\n",
    "\n",
    "    # Encode\n",
    "    x =  tf.nn.conv2d(inputs, padding='SAME')\n",
    "    x = tf.nn.relu(alpha=0.02,x)\n",
    "    x = maxpool2d(x)\n",
    "    \n",
    "#    x = Conv2D(16, 5, padding='same')(x)\n",
    "#    x = LeakyReLU(alpha=0.02)(x)\n",
    "#    x = MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(8, 5, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.02)(x)\n",
    "    encoded = MaxPooling2D(padding='same')(x)    \n",
    "    \n",
    "    # Decode\n",
    "    x = Conv2D(8, 5, padding='same')(encoded)\n",
    "    x = LeakyReLU(alpha=0.02)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    \n",
    "#    x = Conv2D(16, 5, padding='same')(x)\n",
    "#    x = LeakyReLU(alpha=0.02)(x)\n",
    "#    x = UpSampling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, 5, padding='same')(x) \n",
    "    x = LeakyReLU(alpha=0.02)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    \n",
    "    decoded = Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    # Autoencoder\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    \n",
    "    # Compile\n",
    "    autoencoder.compile(optimizer='nadam', loss='binary_crossentropy')\n",
    "    \n",
    "    return autoencoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
